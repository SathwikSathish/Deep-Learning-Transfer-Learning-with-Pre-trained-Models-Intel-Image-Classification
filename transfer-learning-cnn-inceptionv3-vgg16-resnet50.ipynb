{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# TRANSFER LEARNING USING different CNN ARCHITECTURES\n\nThis is a project I have done on computer vision where the dataset considered is Intel Image Classification. I have used this dataset to train models to demonstrate the CONCEPT OF TRANSFER LEARNING in Deep learning.The models used are:\n\n1) INCEPTION V3 (H5 WEIGHTS)\n\n2) INCEPTION V3 (IMAGENET WEIGHTS)\n\n3) VGG 16 (IMAGENET WEIGHTS)\n\n4) VGG 16 (WEIGHTS LOADED FROM A FILE)\n\n5) RESNET50 (IMAGENET WEIGHTS)","metadata":{}},{"cell_type":"markdown","source":"# Preparing the dataset","metadata":{}},{"cell_type":"code","source":"import glob\nimport numpy as np\nimport pandas as pd ","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-07-19T14:21:14.094213Z","iopub.execute_input":"2023-07-19T14:21:14.094721Z","iopub.status.idle":"2023-07-19T14:21:14.100775Z","shell.execute_reply.started":"2023-07-19T14:21:14.094645Z","shell.execute_reply":"2023-07-19T14:21:14.099550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"glob.glob('../input/intel-image-classification/seg_train/seg_train/*')","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:21:14.103516Z","iopub.execute_input":"2023-07-19T14:21:14.103962Z","iopub.status.idle":"2023-07-19T14:21:14.141857Z","shell.execute_reply.started":"2023-07-19T14:21:14.103902Z","shell.execute_reply":"2023-07-19T14:21:14.140876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:21:14.144030Z","iopub.execute_input":"2023-07-19T14:21:14.144727Z","iopub.status.idle":"2023-07-19T14:21:20.786512Z","shell.execute_reply.started":"2023-07-19T14:21:14.144566Z","shell.execute_reply":"2023-07-19T14:21:20.785505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(path,label):\n    x_train=[]\n    y_train=[]\n    all_images_path=glob.glob(path+'/*.jpg')\n    for img_path in all_images_path :\n            img=load_img(img_path, target_size=(150,150))\n            img=img_to_array(img)\n            img=img/255.0\n            x_train.append(img)\n            y_train.append(label)\n    return np.array(x_train),np.array(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:21:20.789817Z","iopub.execute_input":"2023-07-19T14:21:20.790330Z","iopub.status.idle":"2023-07-19T14:21:20.799048Z","shell.execute_reply.started":"2023-07-19T14:21:20.790243Z","shell.execute_reply":"2023-07-19T14:21:20.797618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths=glob.glob('../input/intel-image-classification/seg_train/seg_train/*')\nl=len('../input/intel-image-classification/seg_train/seg_train/')\nlabels=[]\nfor path in paths:\n    labels.append(path[l:])\n    print(labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:21:20.801106Z","iopub.execute_input":"2023-07-19T14:21:20.801683Z","iopub.status.idle":"2023-07-19T14:21:20.820537Z","shell.execute_reply.started":"2023-07-19T14:21:20.801605Z","shell.execute_reply":"2023-07-19T14:21:20.818945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainX_building, trainY_building  = prepare_dataset(\"../input/intel-image-classification/seg_train/seg_train/buildings/\",0)\ntrainX_forest,trainY_forest  = prepare_dataset(\"../input/intel-image-classification/seg_train/seg_train/forest/\",1)\ntrainX_glacier,trainY_glacier  = prepare_dataset(\"../input/intel-image-classification/seg_train/seg_train/glacier/\",2)\ntrainX_mount,trainY_mount  = prepare_dataset(\"../input/intel-image-classification/seg_train/seg_train/mountain/\",3)\ntrainX_sea,trainY_sea  = prepare_dataset(\"../input/intel-image-classification/seg_train/seg_train/sea/\",4)\ntrainX_street,trainY_street  = prepare_dataset(\"../input/intel-image-classification/seg_train/seg_train/street/\",5)\n\nprint('train building shape ', trainX_building.shape, trainY_building.shape) \nprint('train forest', trainX_forest.shape ,trainY_forest.shape)\nprint('train glacier', trainX_glacier.shape,trainY_glacier.shape)\nprint('train mountain', trainX_mount.shape, trainY_mount.shape)\nprint('train sea',     trainX_sea.shape, trainY_sea.shape)\nprint('train street', trainX_street.shape ,trainY_street.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:21:20.822367Z","iopub.execute_input":"2023-07-19T14:21:20.822895Z","iopub.status.idle":"2023-07-19T14:23:55.663538Z","shell.execute_reply.started":"2023-07-19T14:21:20.822818Z","shell.execute_reply":"2023-07-19T14:23:55.661997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train=np.concatenate((trainX_building,trainX_forest,trainX_glacier,trainX_mount,trainX_sea,trainX_street),axis=0)\ny_train=np.concatenate((trainY_building,trainY_forest,trainY_glacier,trainY_mount,trainY_sea,trainY_street),axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:23:55.666973Z","iopub.execute_input":"2023-07-19T14:23:55.667761Z","iopub.status.idle":"2023-07-19T14:23:57.494127Z","shell.execute_reply.started":"2023-07-19T14:23:55.667688Z","shell.execute_reply":"2023-07-19T14:23:57.492954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:23:57.496197Z","iopub.execute_input":"2023-07-19T14:23:57.496959Z","iopub.status.idle":"2023-07-19T14:23:57.504027Z","shell.execute_reply.started":"2023-07-19T14:23:57.496642Z","shell.execute_reply":"2023-07-19T14:23:57.502768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# train_tes_split(x_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:45:32.971049Z","iopub.execute_input":"2023-07-19T14:45:32.971478Z","iopub.status.idle":"2023-07-19T14:45:32.976201Z","shell.execute_reply.started":"2023-07-19T14:45:32.971428Z","shell.execute_reply":"2023-07-19T14:45:32.975214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test Dataset","metadata":{}},{"cell_type":"code","source":"testX_building, testY_building  = prepare_dataset(\"../input/intel-image-classification/seg_test/seg_test/buildings/\",0)\ntestX_forest,testY_forest  = prepare_dataset(\"../input/intel-image-classification/seg_test/seg_test/forest/\",1)\ntestX_glacier,testY_glacier  = prepare_dataset(\"../input/intel-image-classification/seg_test/seg_test/glacier/\",2)\ntestX_mount,testY_mount  = prepare_dataset(\"../input/intel-image-classification/seg_test/seg_test/mountain/\",3)\ntestX_sea,testY_sea  = prepare_dataset(\"../input/intel-image-classification/seg_test/seg_test/sea/\",4)\ntestX_street,testY_street  = prepare_dataset(\"../input/intel-image-classification/seg_test/seg_test/street/\",5)\n\nx_test=np.concatenate((testX_building,testX_forest,testX_glacier,testX_mount,testX_sea,testX_street),axis=0)\ny_test=np.concatenate((testY_building,testY_forest,testY_glacier,testY_mount,testY_sea,testY_street),axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:23:57.520406Z","iopub.execute_input":"2023-07-19T14:23:57.520960Z","iopub.status.idle":"2023-07-19T14:24:26.315968Z","shell.execute_reply.started":"2023-07-19T14:23:57.520853Z","shell.execute_reply":"2023-07-19T14:24:26.314423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Transfer learning - Different approaches","metadata":{}},{"cell_type":"markdown","source":"You can also refer to this link. It has a documentation about fine-tuning the pretrained model\nhttps://keras.io/applications/","metadata":{}},{"cell_type":"markdown","source":"## 2.1 InceptionV3 ","metadata":{}},{"cell_type":"markdown","source":"#### 2.1.1 InceptionV3 with pretrained weights file \n<br>You can find the ptretraiend weight's file here: https://www.kaggle.com/keras/inceptionv3","metadata":{}},{"cell_type":"code","source":"import os\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.optimizers import RMSprop\n\nlocal_weights_file = '/kaggle/input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\npre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n                                include_top = False, \n                                weights = None)\n\npre_trained_model.load_weights(local_weights_file)\n\nfor layer in pre_trained_model.layers:\n     layer.trainable = False\n        \npre_trained_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:46:06.904169Z","iopub.execute_input":"2023-07-19T14:46:06.904849Z","iopub.status.idle":"2023-07-19T14:46:12.850899Z","shell.execute_reply.started":"2023-07-19T14:46:06.904786Z","shell.execute_reply":"2023-07-19T14:46:12.849429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* the name 'mixed7' in below code is a name of one of the layers of Inceptionv3. You can check this out in the summary of the pretraine model by executing ***pre_trained_model.summary()***\n<br><br>PS : You can also choose different layer ","metadata":{}},{"cell_type":"code","source":"last_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\nx = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(6, activation='softmax')(x)           \n\nmodel = Model(pre_trained_model.input, x) \n\nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'sparse_categorical_crossentropy', \n              metrics = ['acc'])\n\nhistory=model.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:24:32.280940Z","iopub.execute_input":"2023-07-19T14:24:32.281361Z","iopub.status.idle":"2023-07-19T14:33:48.113046Z","shell.execute_reply.started":"2023-07-19T14:24:32.281286Z","shell.execute_reply":"2023-07-19T14:33:48.111669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:46:46.619000Z","iopub.execute_input":"2023-07-19T14:46:46.619529Z","iopub.status.idle":"2023-07-19T14:46:46.699735Z","shell.execute_reply.started":"2023-07-19T14:46:46.619447Z","shell.execute_reply":"2023-07-19T14:46:46.697839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><span style=\"color:green\">You can improve the accuracy by changing the architecture of the model <span></div>","metadata":{}},{"cell_type":"markdown","source":"#### 2.2.2 InceptionV3 with inbuilt pretrained weights by the Imagenet","metadata":{}},{"cell_type":"code","source":"import os\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.optimizers import RMSprop\n\n# local_weights_file = '/kaggle/input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\npre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n                                include_top = False, \n                                weights = \"imagenet\")\n\n# pre_trained_model.load_weights(local_weights_file)\n\nfor layer in pre_trained_model.layers:\n     layer.trainable = False\n        \n# pre_trained_model.summary()\nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\nx = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(6, activation='softmax')(x)           \n\nmodel = Model(pre_trained_model.input, x) \n\nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'sparse_categorical_crossentropy', \n              metrics = ['acc'])\n\nhistory=model.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:33:48.115146Z","iopub.execute_input":"2023-07-19T14:33:48.115674Z","iopub.status.idle":"2023-07-19T14:43:12.482145Z","shell.execute_reply.started":"2023-07-19T14:33:48.115577Z","shell.execute_reply":"2023-07-19T14:43:12.480819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:47:14.946442Z","iopub.execute_input":"2023-07-19T14:47:14.946947Z","iopub.status.idle":"2023-07-19T14:47:15.024818Z","shell.execute_reply.started":"2023-07-19T14:47:14.946876Z","shell.execute_reply":"2023-07-19T14:47:15.022852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 VGG16","metadata":{}},{"cell_type":"markdown","source":"#### 2.2.1 : VGG16 with inbuilt pretrained weights by the Imagenet","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\n\npretrained_model=VGG16(input_shape = (150, 150, 3), \n                        include_top = False, \n                        weights = 'imagenet')\n\nfor layer in pretrained_model.layers:\n     layer.trainable = False\n\n# pretrained_model.summary()\nlast_layer = pretrained_model.get_layer('block5_pool')\nprint('last layer of vgg : output shape: ', last_layer.output_shape)\nlast_output= last_layer.output\n\nx = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(6, activation='softmax')(x)           \n\nmodel_vgg = Model(pretrained_model.input, x) \n\n\nmodel_vgg.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'sparse_categorical_crossentropy', \n              metrics = ['acc'])\n\n# model_vgg.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test))\n","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:43:12.484149Z","iopub.execute_input":"2023-07-19T14:43:12.484613Z","iopub.status.idle":"2023-07-19T14:43:14.856876Z","shell.execute_reply.started":"2023-07-19T14:43:12.484528Z","shell.execute_reply":"2023-07-19T14:43:14.855670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2.2.2 : VGG16 with pretrained weights file \nYou will find this file from this link: https://www.kaggle.com/keras/vgg16","metadata":{}},{"cell_type":"code","source":"file='/kaggle/input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\npretrained_model=VGG16(input_shape = (150, 150, 3), \n                        include_top = False, \n                        weights =None)\npretrained_model.load_weights(file)\n\nfor layer in pretrained_model.layers:\n     layer.trainable = False\n\nlast_layer = pretrained_model.get_layer('block5_pool')\nprint('last layer of vgg : output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\nx = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(6, activation='softmax')(x)           \n\nmodel_vgg = Model(pretrained_model.input, x) \n\n\nmodel_vgg.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'sparse_categorical_crossentropy', \n              metrics = ['acc'])\n\n# model_vgg.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:43:14.858131Z","iopub.execute_input":"2023-07-19T14:43:14.858524Z","iopub.status.idle":"2023-07-19T14:43:16.429029Z","shell.execute_reply.started":"2023-07-19T14:43:14.858470Z","shell.execute_reply":"2023-07-19T14:43:16.427181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 ResNet50","metadata":{}},{"cell_type":"markdown","source":"#### 2.3.1 Resnet with inbuilt pretrained weights by the Imagenet","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\n\n#step1\n# file_resnet='/kaggle/input/vgg16/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\npretrained_model=ResNet50( input_shape=(150,150,3),\n                                  include_top=False,\n                                  weights='imagenet'\n                                   )\n#step2\nfor layer in pretrained_model.layers:\n     layer.trainable = False\n\n# pretrained_model.summary()\n        \n#step3        \nlast_layer = pretrained_model.get_layer('conv5_block3_out')\nprint('last layer of vgg : output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\n#step4\nx = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(6, activation='softmax')(x)\n\n#step5\nmodel_resnet = Model(pretrained_model.input, x) \n\n#step6\nmodel_resnet.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'sparse_categorical_crossentropy', \n              metrics = ['acc'])\n\n#step7\n# model_resnet.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test))\n","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:43:16.430583Z","iopub.execute_input":"2023-07-19T14:43:16.431074Z","iopub.status.idle":"2023-07-19T14:43:22.653159Z","shell.execute_reply.started":"2023-07-19T14:43:16.431023Z","shell.execute_reply":"2023-07-19T14:43:22.652135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}